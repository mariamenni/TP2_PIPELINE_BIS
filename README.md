
```markdown
# ğŸŒ TP2 Pipeline BIS â€“ Exploration et Enrichissement GEO

## ğŸ“– 1. PrÃ©sentation du projet

Ce projet a pour objectif dâ€™explorer et dâ€™enrichir des donnÃ©es dâ€™adresses franÃ§aises Ã  lâ€™aide de deux APIs et d'un modÃ¨le d'IA local.

### Sources de donnÃ©es
* ğŸ“ **API Adresse (Base Adresse Nationale - BAN)** : GÃ©ocodage, rÃ©cupÃ©ration latitude/longitude, code postal et ville.
* ğŸ™ï¸ **Geo API Gouv (Communes)** : Enrichissement dÃ©mographique (population, dÃ©partement).

### FonctionnalitÃ©s du pipeline
1.  **GÃ©ocodage et enrichissement** des adresses.
2.  **Transformation et nettoyage** : suppression des doublons, gestion des valeurs manquantes, normalisation.
3.  **Analyse de la qualitÃ©** : complÃ©tude, doublons, score de gÃ©ocodage.
4.  **Visualisation** : carte interactive, population par commune, anomalies.
5.  **Intelligence Artificielle** : Utilisation de **LLaMA 3.2** locale pour gÃ©nÃ©rer des recommandations et du code dâ€™analyse.

---

## âš™ï¸ 2.1 Principe de fonctionnement du pipeline

Le pipeline est conÃ§u **modulaire et reproductible**. Chaque composant a un rÃ´le clair :

1.  **Fetchers (`pipeline/fetchers`)**
    * `AdresseFetcher` : Interroge lâ€™API Adresse (BAN).
    * `CommuneFetcher` : Interroge Geo API Gouv.
    * *BaseFetcher* : GÃ¨re les requÃªtes HTTP, le retry automatique (Tenacity) et le rate limiting.

2.  **ModÃ¨les de donnÃ©es (`pipeline/models.py`)**
    * `GeocodingResult` : RÃ©sultat brut du gÃ©ocodage.
    * `CommuneInfo` : DonnÃ©es administratives.
    * `EnrichedAddress` : Objet fusionnÃ© prÃªt pour l'analyse.

3.  **Enrichisseur (`pipeline/enricher.py`)**
    * `GeoEnricher` coordonne les fetchers. Il gÃ©ocode, rÃ©cupÃ¨re les infos communes et produit les objets enrichis.

4.  **Transformations (`pipeline/transformer.py`)**
    * Nettoyage des donnÃ©es (strip, lower).
    * Traitement des valeurs manquantes (mÃ©diane, moyenne).
    * Interaction avec LLaMA pour des transformations avancÃ©es.

5.  **Analyse de qualitÃ© (`pipeline/quality.py`)**
    * Calcul de la complÃ©tude et des scores.
    * GÃ©nÃ©ration d'un **grade global** (A, B, C) et d'un rapport Markdown.

6.  **Stockage (`pipeline/storage.py`)**
    * Sauvegarde en **JSON** (donnÃ©es brutes) et **Parquet** (donnÃ©es traitÃ©es pour performance).

---

## ğŸ“‚ 2.2 Structure du projet

```text
tp2-exploration/
â”‚
â”œâ”€â”€ .venv/                  # Environnement virtuel Python
â”œâ”€â”€ data/                   # DonnÃ©es
â”‚   â”œâ”€â”€ raw/                # JSON bruts
â”‚   â”œâ”€â”€ processed/          # Fichiers Parquet
â”‚   â””â”€â”€ reports/            # Rapports de qualitÃ© Markdown
â”œâ”€â”€ notebooks/
â”‚   â”œâ”€â”€ exploration.ipynb   # Analyses approfondies, cartes, IA
â”‚   â””â”€â”€ test.ipynb          # Tests rapides du pipeline
â”œâ”€â”€ pipeline/               # Code source du pipeline
â”‚   â”œâ”€â”€ fetchers/           # Modules d'appels API
â”‚   â”œâ”€â”€ models.py           # SchÃ©mas de donnÃ©es
â”‚   â”œâ”€â”€ main.py             # Point d'entrÃ©e
â”‚   â”œâ”€â”€ transformer.py      # Nettoyage
â”‚   â”œâ”€â”€ quality.py          # Analyse qualitÃ©
â”‚   â”œâ”€â”€ storage.py          # I/O
â”‚   â”œâ”€â”€ enricher.py         # Logique d'enrichissement
â”‚   â””â”€â”€ config.py           # Configuration
â”œâ”€â”€ tests/                  # Tests unitaires (pytest)
â”œâ”€â”€ main.py                 # Script d'exÃ©cution rapide
â”œâ”€â”€ pyproject.toml          # DÃ©pendances (uv/poetry)
â””â”€â”€ README.md

```

---

##ğŸ› ï¸ 3. Choix techniques| Composant | Technologie | Justification |
| --- | --- | --- |
| **DonnÃ©es** | API Adresse + Geo API | FiabilitÃ© et complÃ©mentaritÃ© (GÃ©o + DÃ©mographie). |
| **Pipeline** | Python, Pandas | Standard pour la manipulation de donnÃ©es. |
| **Visu** | Plotly | Graphiques et cartes interactives. |
| **IA** | LLaMA 3.2 (Local) | Analyse sÃ©mantique et gÃ©nÃ©ration de code sans fuite de donnÃ©es. |
| **Stockage** | Parquet | Format compressÃ© et rapide pour la lecture/Ã©criture. |
| **Tests** | Pytest | Assure la robustesse des fetchers et transformations. |

---

##ğŸš€ 4. Installation et exÃ©cution

###Cloner le projet```
git clone <repo_url>
cd tp2-exploration

```

###Environnement virtuel```
python -m venv .venv
source .venv/bin/activate   # Linux/macOS
# ou
.venv\Scripts\activate      # Windows

```

###Installation des dÃ©pendances```

uv add httpx pandas duckdb litellm python-dotenv tenacity tqdm pyarrow pydantic pytest

```

###ExÃ©cution du pipelineVia le script principal :

```python
from pipeline.main import run_pipeline_geo

addresses = [
    "10 Rue de Rivoli 75004 Paris",
    "5 Avenue des Champs ElysÃ©es 75008 Paris",
    "1 Place Bellecour 69002 Lyon"
]

stats = run_pipeline_geo(addresses, max_items=10, verbose=True)

```

Ou via les notebooks :

* `jupyter notebook notebooks/exploration.ipynb`
* `jupyter notebook notebooks/test.ipynb`

---

##ğŸ“Š 5. Visualisations incluses*

**Carte interactive** : Latitude/longitude des adresses avec indicateur couleur du score de confiance.
* **Population** : Graphique en barres de la population par commune.
* **Anomalies** : DÃ©tection visuelle des adresses Ã  score faible (<0.5) ou des doublons.

---

##âœ… 6. Tests

Les tests unitaires couvrent l'intÃ©gralitÃ© du pipeline (Fetchers, Transformer, Quality).

Pour lancer les tests avec un rapport de couverture :

```bash
pytest tests/ -v --cov=pipeline --cov-report=html

```

Un rapport HTML sera gÃ©nÃ©rÃ© dans le dossier `htmlcov/`.

---

##ğŸ“ 7. Conclusion

Ce projet illustre lâ€™intÃ©gration de plusieurs APIs pour enrichir des donnÃ©es gÃ©ographiques au sein d'un pipeline modulaire et testable. Lâ€™usage de **LLaMA** apporte une couche d'intelligence pour guider lâ€™analyse, tandis que le format **Parquet** et les visualisations **Plotly** assurent performance et lisibilitÃ©.

```

```
