#ğŸŒ TP2 Pipeline BIS â€“ Exploration et Enrichissement GEO


##ğŸ“– PrÃ©sentation du projet

Ce projet a pour objectif dâ€™explorer et dâ€™enrichir des donnÃ©es dâ€™adresses franÃ§aises en combinant la puissance de deux APIs publiques et l'intelligence artificielle locale.

###Sources de donnÃ©es* 

ğŸ“ **API Adresse (Base Adresse Nationale - BAN)** : GÃ©ocodage, rÃ©cupÃ©ration de la latitude, longitude, code postal et ville.
* ğŸ™ï¸ **Geo API Gouv (Communes)** : Enrichissement dÃ©mographique (population, dÃ©partement, etc.).

###FonctionnalitÃ©s clÃ©s
Le pipeline est entiÃ¨rement automatisÃ© et rÃ©alise les tÃ¢ches suivantes :

1. **GÃ©ocodage et enrichissement** des adresses.
2. **Transformation et nettoyage** (suppression des doublons, gestion des valeurs manquantes, normalisation).
3. **Analyse de la qualitÃ©** (complÃ©tude, dÃ©tection d'anomalies, scoring).
4. **Visualisation** (cartes interactives, graphiques dÃ©mographiques).
5. **Assistance IA** : Utilisation de **LLaMA 3.2** en local pour gÃ©nÃ©rer des recommandations et du code dâ€™analyse.



##âš™ï¸ Architecture du Pipeline
Le pipeline est conÃ§u de maniÃ¨re **modulaire et reproductible**.

###1. Fetchers (`pipeline/fetchers`)
Modules responsables de la rÃ©cupÃ©ration des donnÃ©es. Ils hÃ©ritent d'une classe `BaseFetcher` gÃ©rant les retries (Tenacity) et le rate limiting.

* `AdresseFetcher` : Interroge l'API BAN.
* `CommuneFetcher` : Interroge Geo API Gouv.

###2. ModÃ¨les de donnÃ©es (`pipeline/models.py`)
Utilisation de **Pydantic** pour garantir la structure des donnÃ©es :

* `GeocodingResult` & `CommuneInfo` : DonnÃ©es brutes des APIs.
* `EnrichedAddress` : RÃ©sultat final fusionnÃ©.
* `QualityMetrics` : Indicateurs de qualitÃ© du dataset.

###3. Enrichisseur (`pipeline/enricher.py`)
Le chef d'orchestre `GeoEnricher` coordonne les appels APIs et fusionne les rÃ©sultats tout en maintenant des statistiques d'exÃ©cution.

###4. Transformation (`pipeline/transformer.py`)
Le `DataTransformer` assure la propretÃ© des donnÃ©es :

* Nettoyage des textes (strip, lower).
* Imputation des valeurs manquantes (mÃ©diane, moyenne).
* Interaction avec LLaMA pour suggÃ©rer des transformations.

###5. QualitÃ© & Stockage

**QualityAnalyzer** :
Calcule un score global (A, B, C) basÃ© sur la complÃ©tude et la prÃ©cision du gÃ©ocodage.

**Storage** :
Sauvegarde en **JSON** (brut) et **Parquet** (optimisÃ© pour l'analyse).

---

## ğŸ“‚ Structure du projet

```text
tp2-exploration/
â”‚
â”œâ”€â”€ .venv/                  # Environnement virtuel Python
â”œâ”€â”€ data/                   # DonnÃ©es
â”‚   â”œâ”€â”€ raw/                # JSON bruts
â”‚   â”œâ”€â”€ processed/          # Fichiers Parquet
â”‚   â””â”€â”€ reports/            # Rapports de qualitÃ© Markdown
â”œâ”€â”€ notebooks/
â”‚   â”œâ”€â”€ exploration.ipynb   # Analyses approfondies, cartes, IA
â”‚   â””â”€â”€ test.ipynb          # Tests rapides du pipeline
â”œâ”€â”€ pipeline/               # Code source du pipeline
â”‚   â”œâ”€â”€ fetchers/           # Modules d'appels API
â”‚   â”œâ”€â”€ models.py           # SchÃ©mas de donnÃ©es
â”‚   â”œâ”€â”€ main.py             # Point d'entrÃ©e
â”‚   â”œâ”€â”€ transformer.py      # Nettoyage
â”‚   â”œâ”€â”€ quality.py          # Analyse qualitÃ©
â”‚   â”œâ”€â”€ storage.py          # I/O
â”‚   â”œâ”€â”€ enricher.py         # Logique d'enrichissement
â”‚   â””â”€â”€ config.py           # Configuration
â”œâ”€â”€ tests/                  # Tests unitaires (pytest)
â”œâ”€â”€ main.py                 # Script d'exÃ©cution rapide
â”œâ”€â”€ pyproject.toml          # DÃ©pendances (uv/poetry)
â””â”€â”€ README.md


##ğŸ› ï¸ Choix techniques| Domaine | Technologies | Justification |
| --- | --- | --- |
| **APIs** | API Adresse + Geo API | Combinaison stable pour obtenir prÃ©cision gÃ©ographique et contexte dÃ©mographique. |
| **Core** | Python, Pandas | Standard de l'industrie pour la manipulation de donnÃ©es. |
| **Visu** | Plotly | CrÃ©ation de cartes et graphiques interactifs. |
| **IA** | LLaMA 3.2 (Local) | GÃ©nÃ©ration de code et analyse sÃ©mantique sans envoi de donnÃ©es vers le cloud. |
| **Tests** | Pytest | Assurance qualitÃ© sur les fetchers et les transformations. |
| **Stockage** | Parquet | Format colonnaire compressÃ©, idÃ©al pour les performances d'analyse. |

---

##ğŸš€ Installation et ExÃ©cution###
1. Cloner le projet
git clone <repo_url>
cd tp2-exploration


###2. Environnement virtuel
# CrÃ©ation
python -m venv .venv

# Activation
source .venv/bin/activate   # Linux/macOS
# ou
.venv\Scripts\activate      # Windows



###3. Installation des dÃ©pendances
Ce projet utilise `uv` pour la gestion des paquets.


uv add httpx pandas duckdb litellm python-dotenv tenacity tqdm pyarrow pydantic pytest
# ou via pip
pip install httpx pandas duckdb litellm python-dotenv tenacity tqdm pyarrow pydantic pytest



###4. Utilisation
Vous pouvez lancer le pipeline directement via le script Python :


from pipeline.main import run_pipeline_geo

addresses = [
    "10 Rue de Rivoli 75004 Paris",
    "5 Avenue des Champs ElysÃ©es 75008 Paris",
    "1 Place Bellecour 69002 Lyon"
]

# Lancement du pipeline avec verbose
stats = run_pipeline_geo(addresses, max_items=10, verbose=True)



Ou utiliser les **Notebooks Jupyter** :

jupyter notebook notebooks/exploration.ipynb
jupyter notebook notebooks/test.ipynb



##ğŸ“Š Visualisations et Rapports
Les notebooks gÃ©nÃ¨rent plusieurs types de visualisations :

* ğŸ—ºï¸ **Carte interactive** : Positionnement des adresses avec code couleur selon le score de confiance.
* ğŸ“Š **DÃ©mographie** : Histogramme de la population par commune identifiÃ©e.
* âš ï¸ **Anomalies** : Mise en Ã©vidence des adresses avec un score de gÃ©ocodage faible (<0.5) ou des doublons.



##âœ… TestsLe projet est couvert par des tests unitaires assurant la robustesse du code (Fetchers, Transformer, Quality).

Pour lancer la suite de tests avec rapport de couverture :

pytest tests/ -v --cov=pipeline --cov-report=html



*Le rapport HTML sera disponible dans le dossier `htmlcov/'

##ğŸ“ Conclusion


Ce TP illustre la mise en place d'un pipeline de **Data Engineering moderne** :

1. IntÃ©gration d'APIs tierces.
2. Architecture propre (Separation of Concerns).
3. Utilisation de LLM locaux pour l'aide Ã  l'analyse.
4. Focus sur la qualitÃ© de la donnÃ©e (Data Quality) et la visualisation.
